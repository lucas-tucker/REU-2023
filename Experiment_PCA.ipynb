{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ortho_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/lucastucker/REU-2023/archive/mnist_train.csv\")\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2000)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 2000 # number of MNIST images sampled\n",
    "n = 784 # number of pixels per MNIST image\n",
    "t = 10 # number of neighbors measured\n",
    "sample = data[:m]\n",
    "X = sample[:, 1:].T / 255\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_projection(k, X):\n",
    "    R = np.random.normal(size = (k, n)) \n",
    "    frob_norm = np.linalg.norm(R.T.dot(R).dot(X) - X)\n",
    "    print(f\"frobenius norm for random pca is {frob_norm}\")\n",
    "    return R.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(k, X):\n",
    "    mean_centered_data = X - np.mean(X, axis=1, keepdims=True)\n",
    "    covariance_matrix = np.cov(mean_centered_data) \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    proj = sorted_eigenvectors[:, :k] # top k minimize the frobenius norm\n",
    "    frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "    print(f\"frobenius norm for normal pca is {frob_norm}\")\n",
    "    reduced_data = np.dot(proj.T, mean_centered_data)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is performed according to the gradient calculated in the paper\n",
    "def gradient_pca(k, X, tolerance, step):\n",
    "\n",
    "    X = X - np.mean(X, axis=1, keepdims=True)\n",
    "    XXT = X.dot(X.T)\n",
    "    diff = math.inf\n",
    "    proj = ortho_group.rvs(dim=n)[:, :k] # random n x k orthogonal matrix\n",
    "    norm = np.sqrt(np.linalg.norm(proj))\n",
    "    proj = proj / norm\n",
    "    frob_norm = math.inf\n",
    "\n",
    "    while diff > tolerance:\n",
    "        DF = -2 * XXT.dot(proj)\n",
    "        proj_new = (proj - step * DF) # gradient descent step\n",
    "        proj_new = proj_new / (np.sqrt(np.linalg.norm(proj_new))) # keep normalized -- essential to prevent exploding gradient!\n",
    "        diff = np.linalg.norm(proj - proj_new)\n",
    "        proj = proj_new\n",
    "        # print(f\"diff is {diff}\") # how far we have moved \n",
    "        step = step * (1 + np.exp(-frob_norm / 500))\n",
    "    frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "    print(f\"frobenius norm is {frob_norm}\") # the objective function\n",
    "    reduced_data = np.dot(proj.T, X)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_t_nbrs(t, X):\n",
    "    t_nearest = np.ones((m, t), dtype=int) * 1\n",
    "    for id, row in enumerate(X.T):\n",
    "        dif = X.T - row # get vector representation-wise differences\n",
    "        norm_indices = np.argsort(np.linalg.norm(dif, axis = 1))\n",
    "        t_nearest[id] = norm_indices[1: t + 1]\n",
    "    return t_nearest # returns m x t matrix representing k_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_similarity_score(t, X, X_reduced):\n",
    "    pixelwise_t_nearest = nearest_t_nbrs(t, X)\n",
    "    reduced_t_nearest = nearest_t_nbrs(t, X_reduced)\n",
    "    shared_elems_list = []\n",
    "    for row, row_tilde in zip(pixelwise_t_nearest, reduced_t_nearest):\n",
    "        set_1 = set(row)\n",
    "        set_2 = set(row_tilde)\n",
    "        shared_elem_count = len(set_1.intersection(set_2))\n",
    "        shared_elems_list.append(shared_elem_count)\n",
    "    shared_elems = np.array(shared_elems_list) # row-wise intersection counts\n",
    "    avg_shared = (1/m) * np.sum(shared_elems)\n",
    "    return (avg_shared / t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm for normal pca is 136.04232447143778\n"
     ]
    }
   ],
   "source": [
    "X_pca = get_pca(k, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm for random pca is 84497.79676020994\n"
     ]
    }
   ],
   "source": [
    "X_random = get_random_projection(k, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54435"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_similarity_score(t, X, X_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm is 311.79357289096674\n"
     ]
    }
   ],
   "source": [
    "tol = 0.001 # 0.001\n",
    "step = 0.00001 # 0.00001\n",
    "X_gradient_pca = gradient_pca(k, X, tol, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040850000000000004"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_similarity_score(t, X, X_gradient_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
