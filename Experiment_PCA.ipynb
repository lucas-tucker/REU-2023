{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ortho_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/lucastucker/REU-2023/archive/mnist_train.csv\")\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 2000 # number of MNIST images sampled\n",
    "n = 784 # number of pixels per MNIST image\n",
    "t = 50 # number of neighbors measured\n",
    "sample = data[:m]\n",
    "X = sample[:, 1:].T / 255\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_projection(k, X):\n",
    "    R = np.random.normal(size = (k, n)) \n",
    "    frob_norm = np.linalg.norm(R.T.dot(R).dot(X) - X)\n",
    "    print(f\"frobenius norm for random pca is {frob_norm}\")\n",
    "    return R.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(k, X):\n",
    "    mean_centered_data = X - np.mean(X, axis=1, keepdims=True)\n",
    "    covariance_matrix = np.cov(mean_centered_data) \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    proj = sorted_eigenvectors[:, :k] # top k minimize the frobenius norm\n",
    "    frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "    print(f\"frobenius norm for normal pca is {frob_norm}\")\n",
    "    reduced_data = np.dot(proj.T, mean_centered_data)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is performed according to the gradient calculated in the paper\n",
    "def gradient_pca(k, X, tolerance, step):\n",
    "\n",
    "    X = X - np.mean(X, axis=1, keepdims=True)\n",
    "    diff = math.inf\n",
    "    proj = ortho_group.rvs(dim=n)[:, :k] # random n x k orthogonal matrix\n",
    "    norm = np.linalg.norm(proj)\n",
    "    proj = proj / norm\n",
    "    frob_norm = math.inf\n",
    "    \n",
    "    num_iterations = 20\n",
    "\n",
    "    while diff > tolerance and num_iterations > 0:\n",
    "        DF = 2 * proj.dot(proj.T).dot(X).dot(X.T).dot(proj) - \\\n",
    "        4 * X.dot(X.T).dot(proj) + 2 * X.dot(X.T).dot(proj).dot(proj.T).dot(proj)\n",
    "\n",
    "        DF = DF / np.linalg.norm(DF) # Keep the gradient matrix normalized\n",
    "\n",
    "        proj_new = (proj - step * DF) # gradient descent step\n",
    "        diff = np.linalg.norm(proj - proj_new)\n",
    "        proj = proj_new\n",
    "        num_iterations -= 1\n",
    "        # print(f\"diff is {diff}\") # how far we have moved \n",
    "        # frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "        # print(f\"current frobenius is {frob_norm}\") # current frobenius norm\n",
    "\n",
    "    frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "    print(f\"frobenius norm is {frob_norm}\") # the objective function\n",
    "    reduced_data = np.dot(proj.T, X)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_t_nbrs(t, X):\n",
    "    t_nearest = np.ones((m, t), dtype=int) * 1\n",
    "    for id, row in enumerate(X.T):\n",
    "        dif = X.T - row # get vector representation-wise differences\n",
    "        norm_indices = np.argsort(np.linalg.norm(dif, axis = 1))\n",
    "        t_nearest[id] = norm_indices[1: t + 1]\n",
    "    return t_nearest # returns m x t matrix representing k_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_similarity_score(t, X, X_reduced):\n",
    "    pixelwise_t_nearest = nearest_t_nbrs(t, X)\n",
    "    reduced_t_nearest = nearest_t_nbrs(t, X_reduced)\n",
    "    shared_elems_list = []\n",
    "    for row, row_tilde in zip(pixelwise_t_nearest, reduced_t_nearest):\n",
    "        set_1 = set(row)\n",
    "        set_2 = set(row_tilde)\n",
    "        shared_elem_count = len(set_1.intersection(set_2))\n",
    "        shared_elems_list.append(shared_elem_count)\n",
    "    shared_elems = np.array(shared_elems_list) # row-wise intersection counts\n",
    "    avg_shared = (1/m) * np.sum(shared_elems)\n",
    "    return (avg_shared / t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm for normal pca is 134.98551802433718\n"
     ]
    }
   ],
   "source": [
    "X_pca = get_pca(k, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm for random pca is 88368.25588007383\n"
     ]
    }
   ],
   "source": [
    "X_random = get_random_projection(k, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58653"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_similarity_score(t, X, X_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm is 188.60912789537159\n"
     ]
    }
   ],
   "source": [
    "# got to under 133.5 with tol=0.0001, step=0.01\n",
    "tol = 0.04\n",
    "step = 1\n",
    "X_gradient_pca = gradient_pca(k, X, tol, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7765000000000001"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_similarity_score(t, X, X_gradient_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
