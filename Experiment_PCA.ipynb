{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ortho_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/lucastucker/REU-2023/archive/mnist_train.csv\")\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 2000 # number of MNIST images sampled\n",
    "n = 784 # number of pixels per MNIST image\n",
    "t = 50 # number of neighbors measured\n",
    "sample = data[:m]\n",
    "X = sample[:, 1:].T / 255\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_projection(k, X):\n",
    "    R = np.random.normal(size = (k, n)) \n",
    "    frob_norm = np.linalg.norm(R.T.dot(R).dot(X) - X)\n",
    "    print(f\"frobenius norm for random pca is {frob_norm}\")\n",
    "    return R.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(k, X):\n",
    "    mean_centered_data = X - np.mean(X, axis=1, keepdims=True)\n",
    "    covariance_matrix = np.cov(mean_centered_data) \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    proj = sorted_eigenvectors[:, :k] # top k minimize the frobenius norm\n",
    "    frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "    print(f\"frobenius norm for normal pca is {frob_norm}\")\n",
    "    reduced_data = np.dot(proj.T, mean_centered_data)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is performed according to the gradient calculated in the paper\n",
    "def gradient_pca(k, X, tolerance, step):\n",
    "\n",
    "    X = X - np.mean(X, axis=1, keepdims=True)\n",
    "    XXT = X.dot(X.T)\n",
    "    diff = math.inf\n",
    "    proj = ortho_group.rvs(dim=n)[:, :k] # random n x k orthogonal matrix\n",
    "    norm = np.linalg.norm(proj)\n",
    "    proj = proj / norm\n",
    "    frob_norm = math.inf\n",
    "\n",
    "    while diff > tolerance:\n",
    "        DF = -2 * XXT.dot(proj)\n",
    "        proj_new = (proj - step * DF) # gradient descent step\n",
    "        proj_new = proj_new / (np.linalg.norm(proj_new)) # keep normalized -- essential to prevent exploding gradient!\n",
    "        diff = np.linalg.norm(proj - proj_new)\n",
    "        proj = proj_new\n",
    "        # print(f\"diff is {diff}\") # how far we have moved \n",
    "        # step = step * (1 + np.exp(-frob_norm / 500)) optional to improve performance\n",
    "    frob_norm = np.linalg.norm(proj.dot(proj.T).dot(X) - X)\n",
    "    print(f\"frobenius norm is {frob_norm}\") # the objective function\n",
    "    reduced_data = np.dot(proj.T, X)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_t_nbrs(t, X):\n",
    "    t_nearest = np.ones((m, t), dtype=int) * 1\n",
    "    for id, row in enumerate(X.T):\n",
    "        dif = X.T - row # get vector representation-wise differences\n",
    "        norm_indices = np.argsort(np.linalg.norm(dif, axis = 1))\n",
    "        t_nearest[id] = norm_indices[1: t + 1]\n",
    "    return t_nearest # returns m x t matrix representing k_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_similarity_score(t, X, X_reduced):\n",
    "    pixelwise_t_nearest = nearest_t_nbrs(t, X)\n",
    "    reduced_t_nearest = nearest_t_nbrs(t, X_reduced)\n",
    "    shared_elems_list = []\n",
    "    for row, row_tilde in zip(pixelwise_t_nearest, reduced_t_nearest):\n",
    "        set_1 = set(row)\n",
    "        set_2 = set(row_tilde)\n",
    "        shared_elem_count = len(set_1.intersection(set_2))\n",
    "        shared_elems_list.append(shared_elem_count)\n",
    "    shared_elems = np.array(shared_elems_list) # row-wise intersection counts\n",
    "    avg_shared = (1/m) * np.sum(shared_elems)\n",
    "    return (avg_shared / t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm for normal pca is 135.33232068230524\n"
     ]
    }
   ],
   "source": [
    "X_pca = get_pca(k, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frobenius norm for random pca is 80473.60524843165\n"
     ]
    }
   ],
   "source": [
    "X_random = get_random_projection(k, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56561"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_similarity_score(t, X, X_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff is 1.2199195109599732\n",
      "diff is 0.4187713310779984\n",
      "diff is 0.22937159487463063\n",
      "diff is 0.15528108689135592\n",
      "diff is 0.10481287525564816\n",
      "diff is 0.07017700654901846\n",
      "diff is 0.04706541456486305\n",
      "diff is 0.03176185375786837\n",
      "diff is 0.021587372017553102\n",
      "diff is 0.014768419228317797\n",
      "diff is 0.010159614477641729\n",
      "diff is 0.007020966404123286\n",
      "diff is 0.004869858328497382\n",
      "diff is 0.0033878508357724118\n",
      "diff is 0.0023624833854472556\n",
      "diff is 0.0016506201556971487\n",
      "diff is 0.0011550390849582807\n",
      "diff is 0.0008092571721034223\n",
      "frobenius norm is 308.81256983935054\n"
     ]
    }
   ],
   "source": [
    "tol = 0.001\n",
    "step = 0.01\n",
    "X_gradient_pca = gradient_pca(k, X, tol, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10358"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_similarity_score(t, X, X_gradient_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
