{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb985633e70b4d34aed9a39e26295c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/lucastucker/REU-2023/archive/MNIST/raw/train-images-idx3-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18819d3ee98745f7a95ffa74a036036e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/lucastucker/REU-2023/archive/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba4199a77ca47ab9d14858b9a518d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/lucastucker/REU-2023/archive/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e38054e1bb345269ada6ec1f9741e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/lucastucker/REU-2023/archive/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/lucastucker/REU-2023/archive/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Replace with path to MNIST on your machine\n",
    "train_dataset = datasets.MNIST(\"/Users/lucastucker/REU-2023/archive/\", train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\"/Users/lucastucker/REU-2023/archive/\", train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, criterion, optimizer, train_loader, test_loader, reduced_dim, t_nearest):\n",
    "    for epoch in range(epochs):\n",
    "        train_err = train_epoch(model, criterion, optimizer, train_loader, reduced_dim, t_nearest)\n",
    "        test_err = test(model, test_loader, reduced_dim, t_nearest)\n",
    "        print('Epoch {:03d}/{:03d}, Train Error {:.2f}% || Test Error {:.2f}%'.format(epoch, epochs, train_err*100, test_err*100))\n",
    "    return train_err, test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, criterion, optimizer, loader, reduced_dim, t_nearest):\n",
    "    total_correct = 0.\n",
    "    total_samples = 0.\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # NOTE: Uncomment the code below if you are using a GPU\n",
    "        # if torch.cuda.is_available():\n",
    "        #    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # NEW\n",
    "        num_batches = data.shape[0]\n",
    "        \n",
    "        data = le_on_loader(data.view(784, -1), reduced_dim ** 2, t_nearest)\n",
    "        data = data.reshape(num_batches, 1, reduced_dim, reduced_dim)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        preds = output.argmax(dim=1, keepdim=True)\n",
    "        total_correct += preds.eq(target.view_as(preds)).sum().item() # compare preds to target\n",
    "        total_samples += torch.numel(preds) # numel short for number of elements\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return 1 - total_correct/total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, reduced_dim, t_nearest):\n",
    "    total_correct = 0.\n",
    "    total_samples = 0.\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            # NOTE: Uncomment the code below if you are using a GPU\n",
    "            # if torch.cuda.is_available():\n",
    "            #    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Problem is that le_on_loader depends on batch size\n",
    "            num_batches = data.shape[0]\n",
    "            data = le_on_loader(data.view(784, -1), reduced_dim ** 2, t_nearest).reshape(num_batches, 1, reduced_dim, reduced_dim)\n",
    "\n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1, keepdim=True)\n",
    "            total_correct += preds.eq(target.view_as(preds)).sum().item()\n",
    "            total_samples += preds.numel()\n",
    "\n",
    "    return 1 - total_correct/total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/lucastucker/REU-2023/laplacian_eigenmaps_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_on_loader(X, reduced_dim, t_nearest):\n",
    "    n, m = X.shape\n",
    "    sigma = 0.3 # hyperparameter, 0.2 seems to work best\n",
    "    N = t_nearest_matr(m, t_nearest, X)\n",
    "    W = weight_matr(m, N, X, sigma)\n",
    "    P = get_le_reduced(reduced_dim, X, W)\n",
    "    return torch.FloatTensor(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNeluBN(nn.Module):\n",
    "    def __init__(self, reduced_dim):\n",
    "        super(CNNeluBN, self).__init__()\n",
    "\n",
    "        # write code here to instantiate layers\n",
    "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
    "        # creates a conv layer with 1 input channel, 4 output\n",
    "        # channels, a 3x3 kernel, and stride=padding=1\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(nn.Conv2d(1, 4, 3, 1, 1)) # 1 to 4 channels on 1 x red x red input\n",
    "        self.layers.append(nn.BatchNorm2d(4))\n",
    "        self.layers.append(nn.ELU())\n",
    "        self.layers.append(nn.AvgPool2d(2, 2)) # Now size 4 x red // 2 x red // 2\n",
    "        self.layers.append(nn.Conv2d(4, 8, 3, 1, 1)) # 4 to 8 channels\n",
    "        self.layers.append(nn.BatchNorm2d(8))\n",
    "        self.layers.append(nn.ELU())\n",
    "        self.layers.append(nn.AvgPool2d(2, 2)) # Now size 8 x red // 2 // 2 x red // 2 // 2\n",
    "        new_dim = (reduced_dim // 2) // 2\n",
    "        self.layers.append(nn.Linear(8 * new_dim * new_dim, 10))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                sigma = 1 / (math.sqrt(9 * m.out_channels)) # 9 is k^2\n",
    "                m.weight.data.normal_(0, sigma)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "      # print(input.shape)\n",
    "      u = self.layers[0](input)\n",
    "      for layer in self.layers[1:-1]:\n",
    "         u = layer(u)\n",
    "      num_batches = u.size()[0]\n",
    "      u = u.view(num_batches, -1)\n",
    "      return self.layers[-1](u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() # TODO (implement in nn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ELU CNN + BN with representation dimension 14 x 14\n",
      "train_loader\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[96, 1, 14, 14]' is invalid for input of size 9216",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_loader\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_errs, test_errs \u001b[39m=\u001b[39m train(\u001b[39m3\u001b[39;49m, model, criterion, optimizer, train_loader, test_loader, reduced_dim, t_nearest)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#       X = le_on_loader(input.view(784, -1), reduced_dim, t_nearest)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m  for reduced_dim in range(4, 29, 4):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m  print(\"\\nTraining ELU CNN + BN with {reduced_dim} layers\".format(reduced_dim))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m  train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(epochs, model, criterion, optimizer, train_loader, test_loader, reduced_dim, t_nearest):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         train_err \u001b[39m=\u001b[39m train_epoch(model, criterion, optimizer, train_loader, reduced_dim, t_nearest)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         test_err \u001b[39m=\u001b[39m test(model, test_loader, reduced_dim, t_nearest)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{:03d}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{:03d}\u001b[39;00m\u001b[39m, Train Error \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m || Test Error \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch, epochs, train_err\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, test_err\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m))\n",
      "\u001b[1;32m/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m num_batches \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m data \u001b[39m=\u001b[39m le_on_loader(data\u001b[39m.\u001b[39mview(\u001b[39m784\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), reduced_dim \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, t_nearest)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mreshape(num_batches, \u001b[39m1\u001b[39;49m, reduced_dim, reduced_dim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucastucker/REU-2023/laplacian_eigenmaps_nn_experiment2.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[96, 1, 14, 14]' is invalid for input of size 9216"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "reduced_dim = 14\n",
    "t_nearest = 10\n",
    "print(f\"Training ELU CNN + BN with representation dimension {reduced_dim} x {reduced_dim}\")\n",
    "model = CNNeluBN(reduced_dim) # .cuda() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "print(f\"train_loader\")\n",
    "train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader, reduced_dim, t_nearest)\n",
    "#       X = le_on_loader(input.view(784, -1), reduced_dim, t_nearest)\n",
    "\n",
    "\"\"\"\n",
    "  for reduced_dim in range(4, 29, 4):\n",
    "  print(\"\\nTraining ELU CNN + BN with {reduced_dim} layers\".format(reduced_dim))\n",
    "  model = CNNeluBN(reduced_dim).cuda()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "  train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
