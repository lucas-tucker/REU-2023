{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code draws from the Ray docs at:\n",
    "https://docs.ray.io/en/releases-1.11.0/ray-core/using-ray-with-pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filelock import FileLock\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import ray\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(use_cuda, data_dir):\n",
    "    kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "    with FileLock(\"./data.lock\"):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                data_dir,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])),\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            data_dir,\n",
    "            train=False,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])),\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        **kwargs)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\").item()\n",
    "            pred = output.argmax(\n",
    "                dim=1,\n",
    "                keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return {\n",
    "        \"loss\": test_loss,\n",
    "        \"accuracy\": 100 * correct / len(test_loader.dataset)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/lucastucker/REU-2023/LE_Experiment_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_np(loader):\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "    for data, target in loader:\n",
    "        data = data.view(data.size(0), -1) # Flatten into 784 representation\n",
    "        data_list.append(data.numpy())\n",
    "        target_list.append(target.numpy())\n",
    "    # data_array = np.concatenate(data_list)\n",
    "    # target_array = np.concatenate(target_list)\n",
    "    return data_array, target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LE_on_loader(loader, t = 5, max_rad = 10, sigma = 0.2, proj_dim = 30):        \n",
    "    for data, target in loader:\n",
    "        # print(f\"The size of the data is {data.size()}\")\n",
    "        X = data.view(data.size(0), -1).numpy().T # numpy representation 784 x 128\n",
    "        n, m = X.shape\n",
    "        N = t_nearest_matr(m, max_rad, X)\n",
    "        avgs = avg_distance_matr(m, max_rad, X, N)\n",
    "        W = variable_nbrs_weight(m, max_rad, X, N, avgs)\n",
    "        P = get_le_reduced(proj_dim, X, W)\n",
    "        # print(f\"The shape of P is {P.shape}\")\n",
    "        # print(f\"new data shape is {P.shape}\")\n",
    "        data = torch.from_numpy(P).float()\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.1946672049999237, 'accuracy': 93.96}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, lr=0.01, momentum=0.4, data_dir=\"~/data\"):\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.train_loader, self.test_loader = dataset_creator(use_cuda, data_dir)\n",
    "        \n",
    "        self.train_loader = LE_on_loader(self.train_loader)\n",
    "        self.test_loader = LE_on_loader(self.test_loader)\n",
    "\n",
    "        self.model = Model().to(device)\n",
    "        self.optimizer = optim.SGD(\n",
    "        self.model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    def train(self):\n",
    "        train(self.model, self.device, self.train_loader, self.optimizer)\n",
    "        return test(self.model, self.device, self.test_loader)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.model.load_state_dict(weights)\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data-dir\",\n",
    "    type=str,\n",
    "    default=\"~/data/\",\n",
    "    help=\"Set the path of the dataset.\"\n",
    ")\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "net = Network(data_dir=args.data_dir)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 11:58:35,604\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(Network pid=28148)\u001b[0m /var/folders/33/zckmdctn235gr36g69vrq8sc0000gn/T/ipykernel_16507/99245488.py:12: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Copy.cpp:250.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.15313294439315797, 'accuracy': 95.4},\n",
       " {'loss': 0.19187086760997774, 'accuracy': 94.03}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RemoteNetwork = ray.remote(num_gpus=2)(Network) # convert Network class to Ray Actor class\n",
    "NetworkActor = RemoteNetwork.remote() # Instantiate\n",
    "NetworkActor2 = RemoteNetwork.remote()\n",
    "\n",
    "ray.get([NetworkActor.train.remote(), NetworkActor2.train.remote()]) # Fetch Ray object reference (future)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
